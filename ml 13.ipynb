{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1:\n",
    "\n",
    "Provide an example of the concepts of Prior, Posterior, and Likelihood.\n",
    "\n",
    "Suppose we have a dataset of emails labeled as spam or not spam, and we want to build a machine learning model that can classify new emails as either spam or not spam. Let's say we have a prior belief that 10% of all emails are spam. This is our prior.\n",
    "\n",
    "Now, let's suppose we receive a new email that we want to classify as either spam or not spam. We can use the information from the email to update our prior belief to obtain a posterior belief about whether the email is spam or not. The posterior belief is our updated belief about the probability that the email is spam or not spam, given the information from the email.\n",
    "\n",
    "To calculate the posterior, we use Bayes' theorem, which states that:\n",
    "\n",
    "posterior = (prior * likelihood) / evidence\n",
    "\n",
    "where:\n",
    "\n",
    "prior is our prior belief about the probability that the email is spam or not spam (in this case, 10% that the email is spam and 90% that it is not spam) likelihood is the probability of observing the data (i.e., the words in the email) given that the email is spam or not spam. For example, if the word \"Viagra\" appears in the email, the likelihood that the email is spam increases. evidence is the probability of observing the data, regardless of whether the email is spam or not. This is a normalizing constant that ensures that the posterior probabilities sum to 1. Suppose that the likelihood of observing the words in the email given that it is spam is 0.9, and the likelihood of observing the words in the email given that it is not spam is 0.1. Then, we can calculate the posterior probability that the email is spam as follows:\n",
    "\n",
    "posterior(spam) = (prior(spam) * likelihood(spam)) / evidence\n",
    "\n",
    "= (0.1 * 0.9) / ((0.1 * 0.9) + (0.9 * 0.1))\n",
    "\n",
    "= 0.5\n",
    "\n",
    "So, the posterior probability that the email is spam is 0.5, which means we are uncertain about whether the email is spam or not. If the posterior probability had been greater than 0.5, we would have classified the email as spam, and if it had been less than 0.5, we would have classified it as not spam."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2:\n",
    "\n",
    "What role does Bayes' theorem play in the concept learning principle?\n",
    "\n",
    "Bayes' theorem plays a central role in the concept learning principle known as Bayesian inference. Bayesian inference is a statistical framework that allows us to update our beliefs about a hypothesis in light of new evidence. The framework is based on Bayes' theorem, which states that the probability of a hypothesis given the data is proportional to the probability of the data given the hypothesis multiplied by the prior probability of the hypothesis.\n",
    "\n",
    "In the context of concept learning, Bayesian inference can be used to update our beliefs about the probability of a hypothesis being true (i.e., a particular concept) based on new evidence (i.e., new data). For example, suppose we have a hypothesis that a particular fruit is an apple, and we have some evidence in the form of features such as color, shape, and size. We can use Bayes' theorem to calculate the probability of the hypothesis being true given the evidence, which is known as the posterior probability. This can help us make more informed decisions about the hypothesis, such as whether to accept or reject it.\n",
    "\n",
    "Bayesian inference can also be used in the context of machine learning, where it is used to train models and make predictions. For example, in a Bayesian neural network, the weights of the network are treated as random variables, and the prior probability of the weights is specified using a prior distribution. The likelihood of the data given the weights is then calculated, and Bayes' theorem is used to update the prior distribution of the weights to obtain the posterior distribution. This allows the network to make more informed predictions based on the available data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3:\n",
    "\n",
    "Offer an example of how the Nave Bayes classifier is used in real life.\n",
    "\n",
    "Naive Bayes classifier is a popular algorithm used for text classification, spam filtering, sentiment analysis, and recommendation systems. Here's an example of how Naive Bayes classifier is used in real life for sentiment analysis:\n",
    "\n",
    "Suppose you run a business and you want to know how customers feel about your products based on their feedback on social media. You can use Naive Bayes classifier to classify the sentiment of the feedback as positive, negative or neutral.\n",
    "\n",
    "First, you need to collect a dataset of customer feedback with labels indicating whether the sentiment is positive, negative, or neutral. You can use this dataset to train the Naive Bayes classifier.\n",
    "\n",
    "Next, you can preprocess the feedback by converting it to lowercase, removing stop words, and stemming the words. Then, you can use the bag-of-words model to represent each feedback as a vector of word frequencies. For example, if the feedback is \"I love your product, it's amazing!\", the corresponding vector could be [1, 0, 0, 0, 1, 1], where the first three elements correspond to the words \"I\", \"love\", and \"your\", respectively.\n",
    "\n",
    "Once you have preprocessed the feedback, you can use the Naive Bayes classifier to classify the sentiment of each feedback. The classifier calculates the probability of each sentiment given the words in the feedback, using Bayes' theorem and the assumption of conditional independence between the words. The sentiment with the highest probability is then assigned to the feedback.\n",
    "\n",
    "Finally, you can analyze the results to understand how customers feel about your products. For example, you can calculate the proportion of positive, negative, and neutral feedback, and use this information to improve your products and services.\n",
    "\n",
    "Overall, Naive Bayes classifier is a simple yet effective algorithm for sentiment analysis, and it can be applied to many other tasks where the goal is to classify text data based on its content."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4:\n",
    "\n",
    "Can the Nave Bayes classifier be used on continuous numeric data? If so, how can you go about\n",
    "doing it?\n",
    "\n",
    "Yes, the Naive Bayes classifier can be used on continuous numeric data. There are two main types of Naive Bayes classifiers that can handle continuous data: Gaussian Naive Bayes and Multinomial Naive Bayes.\n",
    "\n",
    "Gaussian Naive Bayes assumes that the continuous data follows a normal distribution, and calculates the probability of the data belonging to each class using the probability density function of the normal distribution. To use Gaussian Naive Bayes on continuous data, you need to first estimate the mean and standard deviation of each feature for each class. Then, given a new data point, you can calculate the probability of the data belonging to each class using the normal distribution with the estimated mean and standard deviation.\n",
    "\n",
    "Multinomial Naive Bayes is typically used for discrete data, but it can also be used for continuous data by discretizing the data into bins. This involves dividing the range of each feature into a fixed number of intervals or bins, and then counting the number of data points that fall into each bin. The frequency counts are then used to estimate the probability of each bin given each class. To use Multinomial Naive Bayes on continuous data, you need to first discretize the data into bins and then calculate the frequency counts for each class.\n",
    "\n",
    "In summary, Naive Bayes classifier can be used on continuous numeric data using Gaussian Naive Bayes or Multinomial Naive Bayes with discretization. However, it's important to note that Naive Bayes classifier has a strong assumption of feature independence, which may not hold for continuous data with high correlations between features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5:\n",
    "\n",
    "What are Bayesian Belief Networks, and how do they work? What are their applications? Are they\n",
    "capable of resolving a wide range of issues?\n",
    "\n",
    "Bayesian Belief Networks (BBNs), also known as Bayesian Networks, are a type of probabilistic graphical model used to represent uncertain knowledge and make probabilistic inferences. BBNs are based on the principles of Bayesian probability theory and graph theory.\n",
    "\n",
    "BBNs consist of nodes representing variables and directed edges representing probabilistic dependencies between variables. Each node is associated with a probability distribution that describes the probability of the node taking on each of its possible states given the states of its parent nodes. The joint probability distribution of all the variables in the network can be calculated using the chain rule of probability.\n",
    "\n",
    "To make inferences in a BBN, we can use a technique called Bayesian inference. Given some observed evidence, we can update the probabilities of the variables in the network using Bayes' theorem, which involves multiplying the prior probabilities of the variables by the likelihood of the evidence given the variables.\n",
    "\n",
    "BBNs have many applications in various fields, such as medical diagnosis, fault diagnosis, risk assessment, decision support, and natural language processing. For example, BBNs can be used to diagnose medical conditions by modeling the symptoms and their probabilities, and making inferences based on the observed symptoms. BBNs can also be used in decision support systems by modeling the consequences of different decisions and their probabilities.\n",
    "\n",
    "BBNs are capable of resolving a wide range of issues, but they have some limitations. BBNs are only as good as the data and assumptions used to construct them, and they require a significant amount of data and expertise to develop and validate. BBNs can also be computationally expensive to evaluate, especially for large and complex networks. Nonetheless, BBNs are a powerful tool for probabilistic reasoning and decision making, and they have shown to be effective in many real-world applications."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6:\n",
    "\n",
    "Passengers are checked in an airport screening system to see if there is an intruder. Let I be the\n",
    "random variable that indicates whether someone is an intruder I = 1) or not I = 0), and A be the variable that indicates alarm I = 0). If an intruder is detected with probability P(A = 1|I = 1) = 0.98 and a non-intruder is detected with probability P(A = 1|I = 0) = 0.001, an alarm will be triggered, implying the error factor. The likelihood of an intruder in the passenger population is P(I = 1) = 0.00001. What are the chances that an alarm would be triggered when an individual is actually an intruder?\n",
    "\n",
    "We want to calculate the probability that an alarm is triggered given that an individual is actually an intruder. This can be expressed as P(A = 1 | I = 1).\n",
    "\n",
    "Using Bayes' theorem, we can write:\n",
    "\n",
    "P(I = 1 | A = 1) = P(A = 1 | I = 1) * P(I = 1) / P(A = 1)\n",
    "\n",
    "We can calculate the denominator P(A = 1) using the law of total probability:\n",
    "\n",
    "P(A = 1) = P(A = 1 | I = 1) * P(I = 1) + P(A = 1 | I = 0) * P(I = 0)\n",
    "\n",
    "We are given that P(A = 1 | I = 1) = 0.98, P(A = 1 | I = 0) = 0.001, and P(I = 1) = 0.00001. Therefore, we can calculate:\n",
    "\n",
    "P(A = 1) = 0.98 * 0.00001 + 0.001 * (1 - 0.00001) = 0.0010898\n",
    "\n",
    "Now we can substitute this into the formula for Bayes' theorem:\n",
    "\n",
    "P(I = 1 | A = 1) = 0.98 * 0.00001 / 0.0010898 = 0.00899\n",
    "\n",
    "Therefore, the probability that an alarm is triggered given that an individual is actually an intruder is approximately 0.00899 or about 0.9%. This means that the screening system has a high error rate in detecting intruders, as it triggers alarms for only a small fraction of the actual intruders."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7:\n",
    "\n",
    "An antibiotic resistance test (random variable T) has 1% false positives (i.e., 1% of those who are\n",
    "not immune to an antibiotic display a positive result in the test) and 5% false negatives (i.e., 1% of those who are not resistant to an antibiotic show a positive result in the test) (i.e. 5 percent of those actually resistant to an antibiotic test negative). Assume that 2% of those who were screened were antibiotic-resistant. Calculate the likelihood that a person who tests positive is actually immune (random variable D).\n",
    "\n",
    "Let D be the random variable that represents whether a person is immune to the antibiotic or not (D=1 if immune, D=0 if not immune), and let T be the random variable that represents the outcome of the antibiotic resistance test (T=1 if positive, T=0 if negative).\n",
    "\n",
    "We want to calculate the probability that a person who tests positive is actually immune, i.e., P(D=1 | T=1).\n",
    "\n",
    "Using Bayes' theorem, we can write:\n",
    "\n",
    "P(D=1 | T=1) = P(T=1 | D=1) * P(D=1) / P(T=1)\n",
    "\n",
    "We need to calculate each of the terms in this formula.\n",
    "\n",
    "First, let's calculate the probability of a positive test result for a person who is actually immune:\n",
    "\n",
    "P(T=1 | D=1) = 1 - 0.05 = 0.95\n",
    "\n",
    "This is because only 5% of people who are immune will test negative, so the probability of a positive result is 1 - 0.05 = 0.95.\n",
    "\n",
    "Next, let's calculate the probability of a person being immune:\n",
    "\n",
    "P(D=1) = 0.02\n",
    "\n",
    "This is given in the problem statement.\n",
    "\n",
    "Now, let's calculate the probability of a positive test result:\n",
    "\n",
    "P(T=1) = P(T=1 | D=1) * P(D=1) + P(T=1 | D=0) * P(D=0)\n",
    "\n",
    "We need to calculate the probability of a positive test result for a person who is not immune:\n",
    "\n",
    "P(T=1 | D=0) = 0.01\n",
    "\n",
    "This is given in the problem statement.\n",
    "\n",
    "We also know that P(D=0) = 1 - P(D=1) = 1 - 0.02 = 0.98.\n",
    "\n",
    "Substituting all these values into the formula for P(T=1), we get:\n",
    "\n",
    "P(T=1) = 0.95 * 0.02 + 0.01 * 0.98 = 0.0292\n",
    "\n",
    "Now we can substitute all these values into the formula for Bayes' theorem:\n",
    "\n",
    "P(D=1 | T=1) = 0.95 * 0.02 / 0.0292 = 0.649\n",
    "\n",
    "Therefore, the likelihood that a person who tests positive is actually immune is approximately 0.649 or about 65%. This means that if a person tests positive for antibiotic resistance, there is still a relatively high chance that they are not actually immune."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8:\n",
    "\n",
    "In order to prepare for the test, a student knows that there will be one question in the exam that\n",
    "is either form A, B, or C. The chances of getting an A, B, or C on the exam are 30 percent, 20%, and 50 percent, respectively. During the planning, the student solved 9 of 10 type A problems, 2 of 10 type B problems, and 6 of 10 type C problems.\n",
    "\n",
    "I What is the likelihood that the student can solve the exam problem?\n",
    "\n",
    "II Given the student's solution, what is the likelihood that the problem was of form A?\n",
    "\n",
    "Let A, B, and C be the events that the exam question is of form A, B, or C, respectively. Let S be the event that the student can solve the exam problem.\n",
    "\n",
    "To find the probability that the student can solve the exam problem, we can use the law of total probability:\n",
    "P(S) = P(S | A) * P(A) + P(S | B) * P(B) + P(S | C) * P(C)\n",
    "\n",
    "From the problem statement, we know that P(A) = 0.3, P(B) = 0.2, and P(C) = 0.5.\n",
    "\n",
    "To find the conditional probabilities P(S | A), P(S | B), and P(S | C), we can use Bayes' theorem:\n",
    "\n",
    "P(S | A) = P(A | S) * P(S) / P(A) = (9/10) * P(S) / 0.3 P(S | B) = P(B | S) * P(S) / P(B) = (2/10) * P(S) / 0.2 P(S | C) = P(C | S) * P(S) / P(C) = (6/10) * P(S) / 0.5\n",
    "\n",
    "We want to find P(S), so we can solve this system of equations:\n",
    "\n",
    "P(S) = P(S | A) * 0.3 + P(S | B) * 0.2 + P(S | C) * 0.5 P(S) = (9/10) * P(S) + (1/10) * P(S) + (3/5) * P(S) P(S) = 0.774\n",
    "\n",
    "Therefore, the likelihood that the student can solve the exam problem is 0.774 or about 77.4%.\n",
    "\n",
    "To find the likelihood that the problem was of form A given the student's solution, we can use Bayes' theorem:\n",
    "P(A | S) = P(S | A) * P(A) / P(S)\n",
    "\n",
    "We already calculated P(S | A) and P(S) in part 1. Substituting these values and the value of P(A) = 0.3, we get:\n",
    "\n",
    "P(A | S) = (9/10) * 0.3 / 0.774 = 0.348\n",
    "\n",
    "Therefore, the likelihood that the problem was of form A given the student's solution is 0.348 or about 34.8%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9:\n",
    "\n",
    "A bank installs a CCTV system to track and photograph incoming customers. Despite the constant\n",
    "influx of customers, we divide the timeline into 5 minute bins. There may be a customer coming into\n",
    "the bank with a 5% chance in each 5-minute time period, or there may be no customer (again, for\n",
    "simplicity, we assume that either there is 1 customer or none, not the case of multiple customers). If\n",
    "\n",
    "there is a client, the CCTV will detect them with a 99 percent probability. If there is no customer, the\n",
    "camera can take a false photograph with a 10% chance of detecting movement from other objects.\n",
    "\n",
    "I How many customers come into the bank on a daily basis (10 hours)?\n",
    "\n",
    "2. On a daily basis, how many fake photographs (photographs taken when there is no\n",
    "customer) and how many missed photographs (photographs taken when there is a customer) are\n",
    "there?\n",
    "\n",
    "3. Explain likelihood that there is a customer if there is a photograph?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The bank is open for 10 hours, which is equivalent to 600 minutes. In each 5-minute period, there is a 5% chance of a customer coming in. Therefore, the expected number of customers in each 5-minute period is 0.05. The total number of 5-minute periods in 10 hours is 1200 (600/5), so we can expect a total of 0.05 x 1200 = 60 customers to come into the bank on a daily basis.\n",
    "\n",
    "2. When there is no customer, there is a 10% chance that the camera will take a false photograph. In each 5-minute period, there is a 95% chance that there will be no customer, so the expected number of false photographs per 5-minute period is 0.1 x 0.95 = 0.095. Therefore, the total number of false photographs on a daily basis is 0.095 x 1200 = 114.\n",
    "\n",
    "When there is a customer, the CCTV will detect them with a 99% probability. In each 5-minute period, there is a 5% chance that there will be a customer, so the expected number of detected photographs per 5-minute period is 0.99 x 0.05 = 0.0495. Therefore, the total number of detected photographs on a daily basis is 0.0495 x 1200 = 59.4. The number of missed photographs (photographs taken when there is a customer but not detected) would be 60 - 59.4 = 0.6.\n",
    "\n",
    "3. If there is a photograph, there are two possibilities: either it was taken when there was a customer, or it was a false photograph. The likelihood of a photograph being taken when there was a customer is 0.05, and the likelihood of a false photograph is 0.095. The total probability of a photograph being taken is the sum of these probabilities: 0.05 + 0.095 = 0.145. If a photograph was taken, the probability that there was a customer is the probability of a customer given that there was a photograph, which is:\n",
    "\n",
    "P(customer | photograph) = P(photograph | customer) * P(customer) / P(photograph)\n",
    "\n",
    "P(photograph | customer) is the probability of a photograph being taken when there was a customer, which is 0.99.\n",
    "\n",
    "P(customer) is the prior probability of a customer coming in, which is 0.05.\n",
    "\n",
    "P(photograph) is the total probability of a photograph being taken, which is 0.145.\n",
    "\n",
    "Therefore, \n",
    "\n",
    "P(customer | photograph) = 0.99 * 0.05 / 0.145 = 0.341\n",
    "\n",
    "So if there is a photograph, the likelihood that there was a customer is 34.1%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10:\n",
    "\n",
    " Create the conditional probability table associated with the node Won Toss in the Bayesian Belief\n",
    "network to represent the conditional independence assumptions of the Nave Bayes classifier for the\n",
    "match winning prediction problem in Section 6.4.4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the conditional probability table (CPT) associated with the node \"Won Toss\" in the Naive Bayes classifier for the match winning prediction problem, we need to represent the conditional independence assumptions. \n",
    "\n",
    "In the Naive Bayes classifier, the assumption is that each feature (or variable) is conditionally independent of the others given the class variable. In this case, the class variable is \"Match Result\" (which can be \"Win\" or \"Lose\"), and the feature is \"Won Toss\" (which can be \"Yes\" or \"No\").\n",
    "\n",
    "The CPT for the node \"Won Toss\" would have two entries, one for each possible value of the class variable (\"Win\" and \"Lose\"). \n",
    "\n",
    "Here is an example of how the CPT might look:\n",
    "\n",
    "| Match Result | P(Won Toss = Yes \\| Match Result) | P(Won Toss = No \\| Match Result) |\n",
    "|--------------|----------------------------------|---------------------------------|\n",
    "| Win          | 0.7                              | 0.3                             |\n",
    "| Lose         | 0.4                              | 0.6                             |\n",
    "\n",
    "The values in the table represent the conditional probabilities of the \"Won Toss\" variable given the corresponding \"Match Result\" value. For example, P(Won Toss = Yes \\| Match Result = Win) is 0.7, indicating that if the match result is a win, there is a 70% probability that the team won the toss.\n",
    "\n",
    "It's important to note that the actual values in the table would need to be determined based on the specific dataset and the probabilities observed in the training data. These values are just an example for illustration purposes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
